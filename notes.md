# Week-Three-Work

## Notes From The Readings

#### https://cradledincaricature.com/2017/05/24/the-soft-digital-history-that-underpins-my-book/

- Already before reading this I am intrigued. I took a two data vizualization classes this year and really enjoyed the concepts, theories and work behind the lessons and projects in both classes.I have expirience working with and creating many vizualizations over the course of the year, but never to repsent historical timelines or information like I imagine will be covered in this weeks work. 

- "Begin constructing and overlaying physical networks (of artists, publishers, customers, advertisers, material suppliers involved in the trade) with representative networks (of places, people, locations found in designs produced by the trade) using ArcGIS (or similar)."
    - I have made node-link diagrams and such, but this is really new to me!
 -"Extract all the listings for businesses associated with printed images (data: 1794, 1808), assign longitude and latitude coordinates to their addresses, and map them (using TileMill rather than ArcGiS; see https://cradledincaricature.com/2012/09/28/week-4-heatmaps/ for more detail)."
    - This is me making a mental note to look into that link later 
- **‘soft’ digital/’digital’/Digital [hH]istory.** : documenting the history you personally care about rather than everything? --> *Will have to come back to this definition later.*
- Space was a very inportant concept when crafting this work
- "Stationers" overpowered the first representation that was made, so it was then filtered out in the second version which lead to the discoveries of more patterns amoung the other 3 categories
    - Do not be afraid to play with the data yu have available (abstract, filter, hide, exclude, etc) as it ight reveal more information of what is important to you or trends thaat were not as easily seen before.
- Spatial patterns are very important... look where points are clustered or how far they are spread out
- "I don’t make an argument within them, rather my thinking – and subsequent source analysis – flowed from constructing them." 
    - This point was pretty impactful, I personally don't often see this kind of idea in thereadings I usually do. Doing the work but not making a point with the result, but rather the process.
    
#### https://cradledincaricature.com/2017/06/06/the-hard-digital-history-that-underpins-my-book/

- "..good History writing is concise, precise, and selective: not telling your reader everything you know is central to how we present interpretations of the past." 
- "The point is, I didn’t leave this digital stuff out because it was digital but rather because leaving stuff out is what we do in the process of turning research into publication."
        - These are 2 really good points to remember. I feel ty are crucial concepts to understand inorder to continue exploring digital history and how to contribute to it!
 - **Hard Digital History** : Work tht is useful to prove a point or finding or theory? It is not neccesssarily things the creator explicitly cares about, but instead helps support their work. (Might need more clarification on this one)
        -" As you will see, ‘visible’ is probably a better word for this as there is nothing ‘hard’ about the Digital History on offer: it doesn’t tell any truths, it doesn’t solve any problems, it doesn’t sit outside of interpretation. Rather – much like any abstraction from primary sources – it does work that I found useful. The only difference is that, on this occasion, I decided to select this work for inclusion in my presentation of the past I care about because it – in part – substantiated my interpretation of that past."
- **"network analysis"** : the mathematical analysis of complex working procedures in terms of a network of related activities.
- It is super crazy th conclusion people can draw out from these vizualizations. Very impressive, my mind would have never seen these things but through the use of the graphic it becomes much clearer.
- "Most explanations for this boil down to the same answer: caricaturists like Isaac Cruikshank did not have free hands in the satires they designed, but rather they made designs that they thought were likely to appeal to the anticipated audiences of one or more prospective publishers."
        - Not the point of this week's work but it is funny that some issues never die. An artists creativity... this is something many creative people in many fields struggle with even today!
- **Corpus Level Work** : corpus, plural corpora A collection of linguistic data, either compiled as written texts or as a transcription of recorded speech. The main purpose of a corpus is to verify a hypothesis about language - for example, to determine how the usage of a particular sound, word, or syntactic construction varies.       
        - I have asked around for clarification for this definition, just to undestand the article properly.
"The digital/’digital’/Digital [hH]istory here may be visible to the reader but it was far from ‘hard’ or – to draw on distinctions made in statistics – the results of data processing were used in an inferential rather than explanatory way."
        - I think it is important to realize that not all data is concrete. Although these are concrete facts in the vizualization, they act as support for a point but not explicitly proving the point right. Just offerin insight as to why the claim is possible.
        - "As a final point, I should add that I’m aware that my network analysis was made and interpreted with caution. Network visualisations are – for the most part – not accurate representations of data. "
- "Historians rarely use phrases like ‘abstraction’ and ‘data models’, but these are things we do and make all the time in our research, just in less formal ways and in formats that are less easy to process as data, to run algorithms against, to visualise, to tabulate, and to reproduce."
        - Good to know! It is good to know that not everything needs to be 100% concrete, as long as there is at least some support in the data and a thourough analysis as to how they arrived there. 
        

## Weekly Tasks

#### REGEX

**Introduction**: *A regular expression (also called regex) is a powerful tool for finding and manipulating text. At its simplest, a regular expression is just a way of looking through texts to locate patterns.*

**Some Basic Principles** : *These are tips and tricks I imagine will be important to know for future work*
    - There are libraries of regular expressions, online.
    - here is a cheatsheet for regular expressions in Sublime Text: https://jdhao.github.io/2019/02/28/sublime_text_regex_cheat_sheet/
    - Very Helpful basic commands are easily listed out in this section, refer to this for future projects as weel
    
**Letters of the Republic of Texas** : The first task this week I must do! Overall, I found this task very informational and I felt I learned alot of valuable techniques is REGEx, that I know will b beneficial for futer work.
        1. Downloading the curl command through the anaconda command prompt was no issue
        2. This next step gave me a few issues, but after scrolling through the discord I discovered it works if I just do the "curl command" in my command prompt rather than anaconda.
        3. The following steps were all do-able with no issues thanks to clear instructions!
        
 #### Open Refine
 
 **Installation** : There were no issues with this first part
 
 **Cleaning and reconciling names** : The steps were easy enough to follow, although I will admit that I was unable to get the numbers for both Senders and Recipients as low as suggested in the instructions. I took the advice that has been constantly given throughout this course, and after 30 minutes I accepted that I had done all the filtering and clustering I could do!
 
 #### Networks
 
**Databasic.io**: I actually have used this before briely, but I am curious to see how it is used in this context.

**UPDATE:** As many others encountered, I seemed to have ran into an issue with databasic.io. After I looked through the discord I learned that many who ran into the same issue ended up using http://hdlab.stanford.edu/palladio-app/#/upload to do this part of this week's work.
        
![Issue](https://github.com/Elissap5100/Week-Three-Work/blob/master/IssueA.PNG)

As mentioned, Palladio does not have as many options as the other program to explore the data. Although, it did a good job in my opinion!

![Issue](https://github.com/Elissap5100/Week-Three-Work/blob/master/ExampleA.PNG)

![Issue](https://github.com/Elissap5100/Week-Three-Work/blob/master/ExampleB.PNG)

**Navigating Gephi**: This has been a very frustrating step, as Gephi would not download properly, and when it finally did it wold not run because it could not find "Java 1 or higher". I managed to find some solutions online, but even navigating those instructions I could not seem to fix it. It is all very frustrating...
    - Here is the link to the forum that delt with this issue: https://github.com/gephi/gephi/issues/1787

![Solution](https://github.com/Elissap5100/Week-Three-Work/blob/master/SolutionP1.PNG)

![Solution](https://github.com/Elissap5100/Week-Three-Work/blob/master/SolutionP2.PNG)

I did as the instructions said and even changed the java code name because it was differently named on my computer, but now when i open the application it doesn't open (at least there is no error code).

Pictures of some of my attempt to do a work around:

![Solution](https://github.com/Elissap5100/Week-Three-Work/blob/master/Attempt1.PNG)

![Solution](https://github.com/Elissap5100/Week-Three-Work/blob/master/Attempt2.PNG)


    
